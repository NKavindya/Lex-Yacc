# Files Explanation

This document provides a comprehensive overview of all files in the DesignProject directory, explaining what each file does, why it's needed, and how it fits into the compiler architecture.

---

## Source Files

### Core Compiler Files

#### `main.c`
**Purpose**: Main entry point for the compiler  
**What it does**:
- Orchestrates the entire compilation process
- Initializes lexer support structures
- Opens source file and invokes parser
- Performs semantic analysis (Pass A: symbol table building, Pass B: type checking)
- Generates code (IR, assembly, machine code) if no errors
- Writes output files (derivation steps, symbol table, errors, tokens, etc.)

**Why we need it**: Coordinates all compiler phases and manages the compilation pipeline from source code to executable code.

**Output files generated**:
- `derivation_steps.txt`: Grammar rule applications during parsing
- `symbol_table.txt`: Complete symbol table dump
- `semantic_errors.txt`: Semantic analysis errors
- `lexer_tokens.txt`: Token trace from lexical analysis
- `lexer_symbols.txt`: Lexical symbol table
- `lexer_errors.txt`: Lexical errors
- `codegen.ir`: Intermediate representation (3-address code)
- `codegen.asm`: x86-32 assembly code
- `codegen.reloc`: Relocatable machine code
- `codegen.abs`: Absolute machine code

---

### Lexical Analysis

#### `scanner.l`
**Purpose**: Lexical analyzer (scanner) definition  
**What it does**:
- Defines token patterns using Flex (Fast Lexical Analyzer Generator)
- Recognizes reserved words, operators, punctuation, identifiers, and literals
- Handles comments (inline `//` and block `/* */`)
- Tracks line and column numbers for error reporting
- Records tokens and symbols for debugging

**Why we need it**: Converts source code character stream into a sequence of tokens that the parser can understand. This is the first phase of compilation.

**Generated files**:
- `lex.yy.c`: C source code for the lexer (generated by Flex)
- `lexer_tokens.txt`: Token trace (written by main.c)
- `lexer_symbols.txt`: Lexical symbol table (written by main.c)
- `lexer_errors.txt`: Lexical errors (written by main.c)

---

### Syntax Analysis

#### `parser.y`
**Purpose**: Parser definition (syntax analyzer)  
**What it does**:
- Defines grammar rules using Bison (GNU Yacc)
- Implements LL(1) grammar transformed from original EBNF grammar
- Builds Abstract Syntax Tree (AST) during parsing
- Logs derivation steps (grammar rule applications)
- Tracks source locations for error reporting

**Why we need it**: Verifies that the sequence of tokens conforms to the language grammar and builds a structured representation (AST) of the source code.

**Generated files**:
- `parser.tab.c`: C source code for the parser (generated by Bison)
- `parser.tab.h`: Header file with token definitions (generated by Bison)
- `derivation_steps.txt`: Grammar rule applications (written during parsing)

**Key features**:
- LL(1) grammar: transformed from EBNF by removing left recursion and EBNF notations
- Right-recursive list productions for EBNF `{{ ... }}` patterns
- Precedence rules for operators
- AST construction for all language constructs

---

### Abstract Syntax Tree

#### `ast.h`
**Purpose**: AST data structure definitions  
**What it does**:
- Defines `NodeKind` enum for all AST node types
- Defines `AST` structure for tree nodes
- Declares functions for AST manipulation (create, append, print, free)

**Why we need it**: Provides a tree representation of the source code's syntactic structure, which is used by semantic analysis and code generation.

**Node types include**:
- Program, class declarations, function declarations
- Statements (if, while, assign, return, read, write)
- Expressions (arithmetic, relational, function calls)
- Types, literals, identifiers

#### `ast.c`
**Purpose**: AST implementation  
**What it does**:
- Implements AST node creation functions
- Implements tree manipulation (append child, append sibling)
- Implements AST printing for debugging
- Implements memory management (free AST)

**Why we need it**: Provides the implementation for AST operations used throughout the compiler.

---

### Lexical Analysis Support

#### `lexer_support.h`
**Purpose**: Lexical analysis support function prototypes  
**What it does**:
- Declares functions for tracking lexical symbols, tokens, and errors
- Defines `LexSymbolKind` enum for symbol categories

**Why we need it**: Provides interface for lexer to record information needed for debugging and error reporting.

#### `lexer_support.c`
**Purpose**: Lexical analysis support implementation  
**What it does**:
- Maintains lexical symbol table (identifiers, literals, reserved words with frequency)
- Maintains token trace (chronological sequence of all tokens)
- Maintains error list (lexical errors encountered)
- Provides functions to dump these structures to files

**Why we need it**: Tracks lexical analysis results for debugging, error reporting, and generating lexical artifacts.

**Data structures**:
- `LexSymbolEntry`: Symbol table entry (lexeme, kind, first occurrence, frequency)
- `TokenRecord`: Token trace entry (token type, name, lexeme, location)
- `LexError`: Error entry (message, location)

---

### Symbol Table

#### `symbol_table.h`
**Purpose**: Symbol table data structure definitions  
**What it does**:
- Defines `SymKind` enum (variable, function, class, parameter, attribute)
- Defines `Symbol` structure (identifier with type, offset, etc.)
- Defines `SymTable` structure (scope with symbols and parent)
- Declares functions for symbol table operations

**Why we need it**: Provides hierarchical symbol table for semantic analysis and code generation. Tracks all identifiers with their types, scopes, and memory locations.

#### `symbol_table.c`
**Purpose**: Symbol table implementation  
**What it does**:
- Implements scope creation and management
- Implements symbol insertion with duplicate detection
- Implements symbol lookup with lexical scoping (search current scope, then parents)
- Calculates stack frame offsets for variables and parameters
- Maintains scope registry for printing all scopes
- Prints symbol table to file

**Why we need it**: Provides the implementation for symbol table operations used by semantic analysis and code generation.

**Key features**:
- Hierarchical scopes (global -> function -> block)
- Stack frame offset calculation (EBP+offset for parameters, EBP-offset for locals)
- Word alignment for x86-32 architecture
- Scope registry for complete symbol table dump

---

### Semantic Analysis

#### `semantic.c`
**Purpose**: Semantic analysis implementation  
**What it does**:
- **Pass A**: Builds symbol tables by traversing AST
  - Creates scopes (global, function, class, block)
  - Inserts symbols (classes, functions, variables, parameters, attributes)
  - Detects duplicate declarations
  - Calculates stack frame offsets
- **Pass B**: Type checking and validation
  - Verifies type compatibility in assignments and operations
  - Checks that all identifiers are declared
  - Validates function calls (correct number and types of arguments)
  - Checks expression types
  - Verifies return types match function signatures

**Why we need it**: Ensures the program is semantically correct (types match, identifiers are declared, function calls are valid) before code generation.

**Error reporting**:
- Collects semantic errors with line numbers
- Writes errors to `semantic_errors.txt`
- Prevents duplicate error messages

---

### Code Generation

#### `codegen.h`
**Purpose**: Code generation function prototypes  
**What it does**:
- Declares functions for generating IR, assembly, and machine code
- Provides interface for code generation from AST

**Why we need it**: Provides interface for code generation phase.

#### `codegen.c`
**Purpose**: Code generation implementation  
**What it does**:
- **IR Generation**: Generates 3-address code (intermediate representation)
  - Format: `result = operand1 operator operand2`
  - Machine-independent representation
- **Assembly Generation**: Generates x86-32 assembly code
  - Function prologues/epilogues
  - Register allocation (EAX, EBX, ECX, EDX, ESI, EDI)
  - Stack frame management (parameters at EBP+8, locals at EBP-offset)
  - Code for expressions, statements, function calls, control flow
- **Machine Code Generation**: Assembles assembly into relocatable and absolute formats

**Why we need it**: Translates AST into executable code. This is the final phase of compilation.

**Architecture**: x86-32 (32-bit x86)
- Word size: 4 bytes
- Stack grows downward
- Calling convention: parameters pushed right-to-left, caller cleans stack
- Registers: EAX, EBX, ECX, EDX, ESI, EDI (general purpose), EBP (frame pointer), ESP (stack pointer)

**Output files**:
- `codegen.ir`: Intermediate representation (3-address code)
- `codegen.asm`: x86-32 assembly code
- `codegen.reloc`: Relocatable machine code (object file format)
- `codegen.abs`: Absolute machine code (executable format)

---

## Documentation Files

### `FilesExplanation.md` (this file)
**Purpose**: Comprehensive documentation of all project files  
**What it does**: Explains the purpose, functionality, and relationships of all files in the project.

**Why we need it**: Helps developers understand the codebase structure and how different components work together.

---

### `BUILD_AND_RUN.md`
**Purpose**: Build and run instructions  
**What it does**: Provides instructions for building the compiler and running it on source files.

**Why we need it**: Essential for users to compile and use the compiler.

---

### `Report.md` / `Report.txt`
**Purpose**: Project report  
**What it does**: Documents the project design, implementation, and results.

**Why we need it**: Provides project documentation and analysis.

---

### `TMA03.md`
**Purpose**: Assignment documentation  
**What it does**: Contains assignment requirements and specifications.

**Why we need it**: Reference for assignment requirements.

---

### `FileStructure.md`
**Purpose**: File structure documentation  
**What it does**: Describes the organization of files in the project.

**Why we need it**: Helps understand project organization.

---

### `TEST_COVERAGE_SUMMARY.md`
**Purpose**: Test coverage documentation  
**What it does**: Documents test files and which grammar rules they cover.

**Why we need it**: Ensures all grammar rules are tested.

---

### `TestResults_Table.md`
**Purpose**: Test results documentation  
**What it does**: Contains test results in tabular format.

**Why we need it**: Tracks test status and results.

---

### `GRAMMAR_LL1_TRANSFORMATION.md`
**Purpose**: Grammar transformation documentation  
**What it does**: Documents the transformation from EBNF to LL(1) grammar.

**Why we need it**: Explains how the grammar was transformed for LL(1) parsing.

---

## Test Files

### `tests/pass/`
**Purpose**: Passing test cases  
**What it does**: Contains source files (`.src`) that should compile successfully.

**Why we need it**: Validates that the compiler correctly handles valid programs.

**Files**: `test01.src` through `test55.src` (55 test files covering all grammar rules)

---

### `tests/error/`
**Purpose**: Error test cases  
**What it does**: Contains source files (`.src`) that should produce errors.

**Why we need it**: Validates that the compiler correctly detects and reports errors.

**Files**: `test01.src` through `test16.src` (16 error test files)

---

## Generated Files (Build Artifacts)

These files are generated during the build process and should not be edited manually:

### Lexer Generated Files
- `lex.yy.c`: C source code for the lexer (generated by Flex from `scanner.l`)

### Parser Generated Files
- `parser.tab.c`: C source code for the parser (generated by Bison from `parser.y`)
- `parser.tab.h`: Header file with token definitions (generated by Bison)

### Object Files
- `*.o`: Object files compiled from `.c` source files

### Executable
- `parser`: Final executable compiler (built from all object files)

---

## Output Files (Generated During Compilation)

These files are generated when the compiler runs on a source file:

### Parsing Output
- `derivation_steps.txt`: Grammar rule applications during parsing (derivation steps)

### Lexical Analysis Output
- `lexer_tokens.txt`: Complete token trace (sequence of all tokens recognized)
- `lexer_symbols.txt`: Lexical symbol table (all identifiers, literals, reserved words with frequency)
- `lexer_errors.txt`: Lexical errors (malformed tokens, unknown characters)

### Semantic Analysis Output
- `symbol_table.txt`: Complete symbol table dump (all scopes and symbols with offsets)
- `semantic_errors.txt`: Semantic errors (type mismatches, undeclared identifiers, etc.)

### Code Generation Output
- `codegen.ir`: Intermediate representation (3-address code)
- `codegen.asm`: x86-32 assembly code
- `codegen.reloc`: Relocatable machine code (object file format)
- `codegen.abs`: Absolute machine code (executable format)

---

## Compiler Architecture Overview

```
Source Code (.src)
    |
    v
[Lexical Analysis] (scanner.l)
    |  Generates tokens
    v
[Syntax Analysis] (parser.y)
    |  Builds AST
    v
[Semantic Analysis] (semantic.c)
    |  Pass A: Build symbol tables
    |  Pass B: Type checking
    v
[Code Generation] (codegen.c)
    |  Generates IR, Assembly, Machine Code
    v
Executable Code
```

### Data Flow

1. **Source Code** → `scanner.l` → **Tokens**
2. **Tokens** → `parser.y` → **AST**
3. **AST** → `semantic.c` (Pass A) → **Symbol Tables**
4. **AST + Symbol Tables** → `semantic.c` (Pass B) → **Validated AST**
5. **AST + Symbol Tables** → `codegen.c` → **IR → Assembly → Machine Code**

---

## File Dependencies

```
main.c
├── ast.h / ast.c
├── symbol_table.h / symbol_table.c
├── lexer_support.h / lexer_support.c
├── codegen.h / codegen.c
├── semantic.c
├── parser.tab.h (generated from parser.y)
└── lex.yy.c (generated from scanner.l)

parser.y
├── ast.h
└── parser.tab.h (generated)

scanner.l
├── parser.tab.h (generated from parser.y)
└── lexer_support.h

semantic.c
├── ast.h
└── symbol_table.h

codegen.c
├── ast.h
└── symbol_table.h
```

---

## Summary

This compiler project implements a complete compiler for a custom programming language, including:

1. **Lexical Analysis**: Tokenizes source code (`scanner.l`)
2. **Syntax Analysis**: Parses tokens and builds AST (`parser.y`)
3. **Semantic Analysis**: Type checking and validation (`semantic.c`)
4. **Code Generation**: Generates IR, assembly, and machine code (`codegen.c`)

All components work together to transform source code into executable machine code, with comprehensive error reporting and debugging support through various output files.



