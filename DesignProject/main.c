/* 
 * main.c - main entry point for the compiler
 * 
 * this file orchestrates the entire compilation process:
 * 1. lexical analysis (tokenization)
 * 2. syntax analysis (parsing and AST construction)
 * 3. semantic analysis (symbol table building and type checking)
 * 4. code generation (IR and assembly)
 */

#include <stdio.h>      // standard i/o functions (printf, fprintf, fopen, etc.)
#include <stdlib.h>     // standard library functions (malloc, free, etc.)
#include "ast.h"        // abstract syntax tree data structures and functions
#include "symbol_table.h" // symbol table management for semantic analysis
#include "lexer_support.h" // lexical analysis support functions
#include "codegen.h"    // code generation functions

/* external declarations from parser.y (generated by Bison) */
extern AST *astRoot;    // root node of the abstract syntax tree (set by parser)
extern int yyparse();   // Bison-generated parser function (returns 0 on success)
extern FILE *yyin;      // input FILE stream for the lexer (set here, used by lexer)

/* global FILE pointer for writing derivation steps during parsing */
FILE *derivation_file = NULL;  // FILE handle for derivation_steps.txt output
FILE *syntax_error_file = NULL; // FILE handle for syntax_error.txt output

/* external declarations from semantic.c */
void semantic_passA(AST *root);      // semantic pass a: build symbol tables
void semantic_passB(AST *root);      // semantic pass b: TYPE checking and validation
int semantic_error_total(void);       // returns total count of semantic errors
extern SymTable *globalTable;        // global symbol table (created in semantic.c)
extern FILE *errFile;                // FILE handle for semantic error output

/**
 * main - compiler entry point
 * 
 * compilation pipeline:
 * 1. initialize lexer support structures
 * 2. open source file and set up lexer input
 * 3. parse source code (builds AST)
 * 4. perform semantic analysis (build symbol tables, check types)
 * 5. generate code (IR, assembly, machine code) if no errors
 * 
 * @param argc number of command-line arguments
 * @param argv command-line arguments (argv[1] should be source file path)
 * @return 0 on success, 1 on error
 */
int main(int argc, char **argv) {
    // initialize lexer support: set up data structures for token/symbol tracking
    lex_support_init();
    
    // check command-line arguments: require source FILE path
    if (argc < 2) {
        fprintf(stderr, "Usage: %s <sourcefile>\n", argv[0]);
        return 1;
    }
    
    // open source FILE for reading
    FILE *f = fopen(argv[1], "r");
    if (!f) { 
        perror("fopen");  // print system error message
        return 1; 
    }
    yyin = f;  // set lexer input stream to source FILE

    // open FILE for writing derivation steps (grammar rule applications during parsing)
    derivation_file = fopen("derivation_steps.txt", "w");
    // open FILE for syntax errors (truncate each run)
    syntax_error_file = fopen("syntax_error.txt", "w");

    // phase 1: syntax analysis (parsing)
    // invoke Bison-generated parser: tokenizes input and builds AST
    // returns 0 on success, non-zero on syntax error
    if (yyparse() != 0) {
        fprintf(stderr, "Parsing failed.\n");
        fclose(f);
        if (derivation_file) fclose(derivation_file);
        if (syntax_error_file) fclose(syntax_error_file);
        lex_support_finalize();  // clean up lexer data structures
        return 1;
    }
    fclose(f);  // close source FILE (parsing complete)
    if (derivation_file) fflush(derivation_file);  // ensure derivation steps are written

    // verify AST was created successfully
    if (!astRoot) {
        fprintf(stderr, "No AST produced.\n");
        if (derivation_file) fclose(derivation_file);
        if (syntax_error_file) fclose(syntax_error_file);
        lex_support_finalize();
        return 1;
    }

    // print AST structure to stdout for debugging/inspection
    printf("=== AST ===\n");
    ast_print(astRoot, 0);  // print AST starting at root with 0 indentation

    // phase 2: semantic analysis
    // open FILE for semantic error messages
    errFile = fopen("semantic_errors.txt", "w");
    if (!errFile) errFile = stdout;  // fallback to stdout IF FILE open fails

    // semantic pass a: build symbol tables
    // traverses AST and creates symbol table entries for:
    // - classes, functions, variables, parameters, attributes
    // - establishes scope hierarchy (global -> function -> block scopes)
    semantic_passA(astRoot);

    // WRITE symbol table to FILE for inspection
    FILE *symout = fopen("symbol_table.txt", "w");
    if (symout) {
        symtable_print_all(globalTable, symout);  // print all scopes and symbols
        fclose(symout);
    }

    // semantic pass b: TYPE checking and validation
    // checks for:
    // - TYPE mismatches in assignments and operations
    // - undeclared identifiers
    // - wrong number of function arguments
    // - variable redeclarations
    semantic_passB(astRoot);
    int semanticErrors = semantic_error_total();  // get total error count

    // phase 3: output lexical analysis artifacts
    // WRITE lexical symbol table (all identifiers, literals, reserved words found)
    FILE *lexsym = fopen("lexer_symbols.txt", "w");
    if (lexsym) {
        lex_support_dump_symbols(lexsym);  // dump symbol frequency and location info
        fclose(lexsym);
    }
    
    // WRITE token trace (sequence of all tokens recognized during lexing)
    FILE *toklog = fopen("lexer_tokens.txt", "w");
    if (toklog) {
        lex_support_dump_tokens(toklog);  // dump all tokens with line/column positions
        fclose(toklog);
    }
    
    // WRITE lexical errors (malformed tokens, unknown characters, etc.)
    FILE *lexerr = fopen("lexer_errors.txt", "w");
    if (lexerr) {
        lex_support_dump_errors(lexerr);  // dump all lexical errors encountered
        fclose(lexerr);
    }
    
    // clean up lexer data structures (free memory)
    lex_support_finalize();

    // phase 4: code generation (only IF no semantic errors)
    if (semanticErrors == 0) {
        // generate intermediate representation (3-address code)
        // IR is machine-independent representation between AST and assembly
        if (codegen_generate_ir(astRoot, globalTable, "codegen.ir") == 0) {
            printf("Intermediate Representation written to codegen.ir\n");
        }
        
        // generate x86-32 assembly code from AST
        // uses symbol table for variable offsets and function information
        if (codegen_generate(astRoot, globalTable, "codegen.asm") == 0) {
            printf("Assembly code written to codegen.asm\n");
        } else {
            fprintf(stderr, "Code generation failed.\n");
        }
    } else {
        // skip code generation IF semantic errors exist
        printf("Skipping code generation due to %d semantic error(s).\n", semanticErrors);
    }

    // cleanup: close FILE handles
    if (errFile && errFile != stdout) fclose(errFile);
    if (derivation_file) fclose(derivation_file);
    if (syntax_error_file) fclose(syntax_error_file);

    // print summary of output files generated
    printf("Done. See lexer_tokens.txt, lexer_symbols.txt, semantic_errors.txt, symbol_table.txt");
    if (semanticErrors == 0) {
        printf(", codegen.ir, codegen.asm");
    }
    printf("\n");
    return 0;  // success
}
